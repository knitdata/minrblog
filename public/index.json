[{"authors":["admin"],"categories":null,"content":"My name is Min R Tamang. I am a quality engineer at Kite Hill. Professionally my responsibilities included developing and deploying statistical process control to documentation and data analysis.\nI hold a Master\u0026rsquo;s degree in Statistics with concentration in Data Science from Cal State Bay. I also earned Bachelor\u0026rsquo;s degree in Biological Science and Associate degree in Natural Science from Southeast Missouri State University and Quincy College respectively. Additionally, I completed Bachelor\u0026rsquo;s degree from Tribhuvan University, Kathmandu.\nI was born in Nepal. Currently I live in Bay Area, California.\nThis is a data science blog built with R package blogdown, Hugo, GitHub, and deployed through Netlify. If you like my posts or have a feedback, please leave a comment.\n","date":1554595200,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"My name is Min R Tamang. I am a quality engineer at Kite Hill. Professionally my responsibilities included developing and deploying statistical process control to documentation and data analysis.\nI hold a Master\u0026rsquo;s degree in Statistics with concentration in Data Science from Cal State Bay.","tags":null,"title":"","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":[],"content":" The TF-IDF is computed by multiplying two terms:TF and IDF. TF is the normalized term frequency and IDF is the inverse document frequency. Therefore, the formula for TF-IDF is TFxIDF\nwhere, \\[\\text{TF} = (\\frac{\\text{number of times term appears in a document}}{\\text{Total number of terms in the document}})\\] and \\[\\text{IDF} = \\ln(\\frac{n_{\\text{ documents }}}{n_{\\text{document containing term}}})\\] TF-IDF can be used for ranking important documents(page ranking). For example when we google a term COVID-19, the results are displayed in order of relevance. TF-IDF gives searched word(COVID-19) a higher score.\nTF-IDF on Gutenberg books library(pacman) p_load(gutenbergr,tidyr,tidyverse,tidytext,forcats, genius) #books on mathematics from project glutenberg math_books \u0026lt;- gutenberg_download(c(16449,25664,17001,16713), meta_fields = \u0026quot;title\u0026quot;) ## Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest ## Using mirror http://aleph.gutenberg.org #frequencies of words in each book math_words \u0026lt;- math_books %\u0026gt;% unnest_tokens(word, text) %\u0026gt;% count(title, word, sort = TRUE) math_words ## # A tibble: 24,655 x 3 ## title word n ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 Amusements in Mathematics the 12480 ## 2 Amusements in Mathematics of 4908 ## 3 Amusements in Mathematics and 3921 ## 4 Amusements in Mathematics a 3833 ## 5 Amusements in Mathematics in 3672 ## 6 Amusements in Mathematics to 3598 ## 7 The Number Concept: Its Origin and Development the 3177 ## 8 An Elementary Course in Synthetic Projective Geometry the 2750 ## 9 The Earliest Arithmetics in English e 2579 ## 10 Amusements in Mathematics is 2542 ## # … with 24,645 more rows #tf-idf tfidf_mathbooks \u0026lt;- math_words %\u0026gt;% bind_tf_idf(word, title, n) %\u0026gt;% mutate(word = fct_reorder(word, tf_idf)) %\u0026gt;% mutate(title = factor(title, levels = c( \u0026quot;The Number Concept: Its Origin and Development\u0026quot;,\u0026quot;The Earliest Arithmetics in English\u0026quot;, \u0026quot;An Elementary Course in Synthetic Projective Geometry\u0026quot;,\u0026quot;Amusements in Mathematics\u0026quot;))) tfidf_mathbooks ## # A tibble: 24,655 x 6 ## title word n tf idf tf_idf ## \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Amusements in Mathematics the 12480 0.0753 0 0 ## 2 Amusements in Mathematics of 4908 0.0296 0 0 ## 3 Amusements in Mathematics and 3921 0.0237 0 0 ## 4 Amusements in Mathematics a 3833 0.0231 0 0 ## 5 Amusements in Mathematics in 3672 0.0222 0 0 ## 6 Amusements in Mathematics to 3598 0.0217 0 0 ## 7 The Number Concept: Its Origin and Developme… the 3177 0.0578 0 0 ## 8 An Elementary Course in Synthetic Projective… the 2750 0.0788 0 0 ## 9 The Earliest Arithmetics in English e 2579 0.0527 0.288 0.0151 ## 10 Amusements in Mathematics is 2542 0.0153 0 0 ## # … with 24,645 more rows #bargraphs tfidf_mathbooks %\u0026gt;% group_by(title) %\u0026gt;% top_n(15, tf_idf) %\u0026gt;% ungroup() %\u0026gt;% mutate(word = reorder(word, tf_idf)) %\u0026gt;% ggplot(aes(word, tf_idf, fill = title)) + geom_col(show.legend = FALSE) + labs(x = NULL, y = \u0026quot;tf-idf\u0026quot;) + facet_wrap(~title, ncol = 2, scales = \u0026quot;free\u0026quot;) + coord_flip() + ggtitle(\u0026quot;Bargraphs of top 15 words\u0026quot;) Amusements in Mathematics - This book appears to be related to solving puzzle and game.\nAn Elementary Course in Synthetic Projective Geometry- It appears to be related to book about measuring angle and point, probably involve a lot of theories.\nThe Earliest Arithmetics in English - The terms are interesting. The words in various langauge in original form.\nThe Number Concept: Its Origin and Development - It appears to be related how counting and numbering originated. It is probably indicating use of fingers by tribes for counting.\n*Same analysis using bigrams.\n# bigrams for the math books from previous problem math_bigrams \u0026lt;- math_books %\u0026gt;% unnest_tokens(bigram, text, token = \u0026quot;ngrams\u0026quot;, n = 2) math_bigrams ## # A tibble: 304,593 x 3 ## gutenberg_id title bigram ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 16449 The Number Concept: Its Origin and Development transcriber\u0026#39;s no… ## 2 16449 The Number Concept: Its Origin and Development note the ## 3 16449 The Number Concept: Its Origin and Development the following ## 4 16449 The Number Concept: Its Origin and Development following errors ## 5 16449 The Number Concept: Its Origin and Development errors found ## 6 16449 The Number Concept: Its Origin and Development found in ## 7 16449 The Number Concept: Its Origin and Development in the ## 8 16449 The Number Concept: Its Origin and Development the original ## 9 16449 The Number Concept: Its Origin and Development original have ## 10 16449 The Number Concept: Its Origin and Development have been ## # … with 304,583 more rows # count bigrams math_bigrams %\u0026gt;% count(bigram, sort = TRUE) ## # A tibble: 126,537 x 2 ## bigram n ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 of the 2866 ## 2 in the 1850 ## 3 o o 1044 ## 4 to the 847 ## 5 it is 758 ## 6 and the 756 ## 7 on the 677 ## 8 the same 638 ## 9 that the 627 ## 10 to be 554 ## # … with 126,527 more rows # separate and filter stop words mathbigrams_separated \u0026lt;- math_bigrams %\u0026gt;% separate(bigram, c(\u0026quot;word1\u0026quot;, \u0026quot;word2\u0026quot;), sep = \u0026quot; \u0026quot;) mathbigrams_filtered \u0026lt;- mathbigrams_separated %\u0026gt;% filter(!word1 %in% stop_words$word) %\u0026gt;% filter(!word2 %in% stop_words$word) # new bigram counts bigram_counts \u0026lt;- mathbigrams_filtered %\u0026gt;% count(word1, word2, sort = TRUE) bigram_counts ## # A tibble: 38,184 x 3 ## word1 word2 n ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 1 2 217 ## 2 2 3 176 ## 3 3 4 167 ## 4 4 5 123 ## 5 2 1 114 ## 6 5 6 113 ## 7 ou er 111 ## 8 1 7 103 ## 9 2 2 101 ## 10 2 8 101 ## # … with 38,174 more rows #combine filtered words to form bigrams mathbigrams_united \u0026lt;- mathbigrams_filtered %\u0026gt;% unite(bigram, word1, word2, sep = \u0026quot; \u0026quot;) mathbigrams_united ## # A tibble: 56,991 x 3 ## gutenberg_id title bigram ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 16449 The Number Concept: Its Origin and Development transcriber\u0026#39;s no… ## 2 16449 The Number Concept: Its Origin and Development errors found ## 3 16449 The Number Concept: Its Origin and Development 14th paragraph ## 4 16449 The Number Concept: Its Origin and Development paragraph drop ## 5 16449 The Number Concept: Its Origin and Development drop double ## 6 16449 The Number Concept: Its Origin and Development double quote ## 7 16449 The Number Concept: Its Origin and Development chapter iv ## 8 16449 The Number Concept: Its Origin and Development iv 1st ## 9 16449 The Number Concept: Its Origin and Development 1st paragraph ## 10 16449 The Number Concept: Its Origin and Development chapter iv ## # … with 56,981 more rows bigram_tf_idf \u0026lt;- mathbigrams_united %\u0026gt;% count(title, bigram) %\u0026gt;% bind_tf_idf(bigram, title, n) %\u0026gt;% arrange(desc(tf_idf)) bigram_tf_idf ## # A tibble: 38,958 x 6 ## title bigram n tf idf tf_idf ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 The Earliest Arithmetics in English ou er 111 0.00929 1.39 0.0129 ## 2 The Earliest Arithmetics in English fig ur 86 0.00720 1.39 0.00998 ## 3 An Elementary Course in Synthetic Pro… _a_ _b_ 31 0.00576 1.39 0.00799 ## 4 The Earliest Arithmetics in English ne er 58 0.00485 1.39 0.00673 ## 5 An Elementary Course in Synthetic Pro… _b_ _c_ 26 0.00483 1.39 0.00670 ## 6 An Elementary Course in Synthetic Pro… line join… 22 0.00409 1.39 0.00567 ## 7 The Number Concept: Its Origin and De… _op cit 70 0.00397 1.39 0.00550 ## 8 An Elementary Course in Synthetic Pro… letter ga… 21 0.00390 1.39 0.00541 ## 9 The Earliest Arithmetics in English aft er 46 0.00385 1.39 0.00534 ## 10 The Earliest Arithmetics in English eu er 46 0.00385 1.39 0.00534 ## # … with 38,948 more rows #bargraphs bigram_tf_idf %\u0026gt;% group_by(title) %\u0026gt;% top_n(15, tf_idf) %\u0026gt;% ungroup() %\u0026gt;% mutate(bigram=reorder(bigram, tf_idf)) %\u0026gt;% ggplot(aes(bigram, tf_idf, fill = title)) + geom_col(show.legend = FALSE) + labs(x = NULL, y = \u0026quot;tf-idf\u0026quot;) + facet_wrap(~title, ncol = 2, scales = \u0026quot;free\u0026quot;) + coord_flip() + ggtitle(\u0026quot;Bargraphs of top 15 bigrams\u0026quot;)  Sentiment analysis on the songs from Genius Aerosmith - I don’t want to miss a thing  #get song lyrics aero_smith_i_don \u0026lt;- genius_lyrics(artist = \u0026quot;Aerosmith\u0026quot;, song = \u0026quot; I don\u0026#39;t want to miss a thing\u0026quot;) aero_smith_i_don ## # A tibble: 59 x 3 ## track_title line lyric ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 I Don’t Want to Miss a T… 1 I could stay awake just to hear you breathin\u0026#39; ## 2 I Don’t Want to Miss a T… 2 Watch you smile while you are sleeping ## 3 I Don’t Want to Miss a T… 3 While you\u0026#39;re far away and dreaming ## 4 I Don’t Want to Miss a T… 4 I could spend my life in this sweet surrender ## 5 I Don’t Want to Miss a T… 5 I could stay lost in this moment forever ## 6 I Don’t Want to Miss a T… 6 Where every moment spent with you is a momen… ## 7 I Don’t Want to Miss a T… 7 Don\u0026#39;t want to close my eyes ## 8 I Don’t Want to Miss a T… 8 I don\u0026#39;t want to fall asleep ## 9 I Don’t Want to Miss a T… 9 \u0026#39;Cause I\u0026#39;d miss you, baby ## 10 I Don’t Want to Miss a T… 10 And I don\u0026#39;t wanna miss a thing ## # … with 49 more rows #tidy up lyrics i_dont_tidy \u0026lt;- aero_smith_i_don %\u0026gt;% select(lyric, track_title) %\u0026gt;% unnest_tokens(word, lyric) i_dont_tidy ## # A tibble: 390 x 2 ## track_title word ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 I Don’t Want to Miss a Thing i ## 2 I Don’t Want to Miss a Thing could ## 3 I Don’t Want to Miss a Thing stay ## 4 I Don’t Want to Miss a Thing awake ## 5 I Don’t Want to Miss a Thing just ## 6 I Don’t Want to Miss a Thing to ## 7 I Don’t Want to Miss a Thing hear ## 8 I Don’t Want to Miss a Thing you ## 9 I Don’t Want to Miss a Thing breathin ## 10 I Don’t Want to Miss a Thing watch ## # … with 380 more rows # join with sentiment lexicon i_dont_sentiments\u0026lt;- i_dont_tidy%\u0026gt;% inner_join(get_sentiments(\u0026quot;bing\u0026quot;), by = c(word = \u0026quot;word\u0026quot;)) i_dont_sentiments ## # A tibble: 35 x 3 ## track_title word sentiment ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 I Don’t Want to Miss a Thing smile positive ## 2 I Don’t Want to Miss a Thing sweet positive ## 3 I Don’t Want to Miss a Thing surrender negative ## 4 I Don’t Want to Miss a Thing lost negative ## 5 I Don’t Want to Miss a Thing treasure positive ## 6 I Don’t Want to Miss a Thing fall negative ## 7 I Don’t Want to Miss a Thing miss negative ## 8 I Don’t Want to Miss a Thing miss negative ## 9 I Don’t Want to Miss a Thing miss negative ## 10 I Don’t Want to Miss a Thing miss negative ## # … with 25 more rows #bargraph word-sentiment i_dont_sentiments %\u0026gt;% count(sentiment, word) %\u0026gt;% ungroup() %\u0026gt;% mutate(n = ifelse(sentiment == \u0026quot;negative\u0026quot;, -n, n)) %\u0026gt;% mutate(word = reorder(word, n)) %\u0026gt;% ggplot(aes(word, n, fill = sentiment)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + ylab(\u0026quot;Contribution to sentiment\u0026quot;) + coord_flip() The Weeknd - Earned It  the_weeknd_earned_it \u0026lt;- genius_lyrics(artist = \u0026quot;The Weeknd\u0026quot;, song = \u0026quot;Earned It\u0026quot;) the_weeknd_earned_it ## # A tibble: 51 x 3 ## track_title line lyric ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 Earned It (Fifty Shades of Gr… 1 I\u0026#39;ma care for you ## 2 Earned It (Fifty Shades of Gr… 2 I\u0026#39;ma care for you, you, you, you ## 3 Earned It (Fifty Shades of Gr… 3 You make it look like it\u0026#39;s magic (Oh ye… ## 4 Earned It (Fifty Shades of Gr… 4 \u0026#39;Cause I see nobody, nobody but you, yo… ## 5 Earned It (Fifty Shades of Gr… 5 I\u0026#39;m never confused ## 6 Earned It (Fifty Shades of Gr… 6 Hey, hey ## 7 Earned It (Fifty Shades of Gr… 7 I\u0026#39;m so used to bein\u0026#39; used ## 8 Earned It (Fifty Shades of Gr… 8 So I love when you call unexpected ## 9 Earned It (Fifty Shades of Gr… 9 \u0026#39;Cause I hate when the moment\u0026#39;s expected ## 10 Earned It (Fifty Shades of Gr… 10 So I\u0026#39;ma care for you, you, you ## # … with 41 more rows earned_it_tidy \u0026lt;- the_weeknd_earned_it %\u0026gt;% select(lyric, track_title) %\u0026gt;% unnest_tokens(word, lyric) earned_it_tidy ## # A tibble: 325 x 2 ## track_title word ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Earned It (Fifty Shades of Grey) i\u0026#39;ma ## 2 Earned It (Fifty Shades of Grey) care ## 3 Earned It (Fifty Shades of Grey) for ## 4 Earned It (Fifty Shades of Grey) you ## 5 Earned It (Fifty Shades of Grey) i\u0026#39;ma ## 6 Earned It (Fifty Shades of Grey) care ## 7 Earned It (Fifty Shades of Grey) for ## 8 Earned It (Fifty Shades of Grey) you ## 9 Earned It (Fifty Shades of Grey) you ## 10 Earned It (Fifty Shades of Grey) you ## # … with 315 more rows earned_it_sentiments\u0026lt;- earned_it_tidy%\u0026gt;% inner_join(get_sentiments(\u0026quot;bing\u0026quot;), by = c(word = \u0026quot;word\u0026quot;)) earned_it_sentiments ## # A tibble: 36 x 3 ## track_title word sentiment ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Earned It (Fifty Shades of Grey) like positive ## 2 Earned It (Fifty Shades of Grey) magic positive ## 3 Earned It (Fifty Shades of Grey) confused negative ## 4 Earned It (Fifty Shades of Grey) love positive ## 5 Earned It (Fifty Shades of Grey) unexpected negative ## 6 Earned It (Fifty Shades of Grey) hate negative ## 7 Earned It (Fifty Shades of Grey) perfect positive ## 8 Earned It (Fifty Shades of Grey) worth positive ## 9 Earned It (Fifty Shades of Grey) work positive ## 10 Earned It (Fifty Shades of Grey) love positive ## # … with 26 more rows earned_it_sentiments %\u0026gt;% count(sentiment, word) %\u0026gt;% ungroup() %\u0026gt;% mutate(n = ifelse(sentiment == \u0026quot;negative\u0026quot;, -n, n)) %\u0026gt;% mutate(word = reorder(word, n)) %\u0026gt;% ggplot(aes(word, n, fill = sentiment)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + ylab(\u0026quot;Contribution to sentiment\u0026quot;) + coord_flip() Pharrell Williams - Happy  pharrell_will_happy \u0026lt;- genius_lyrics(artist = \u0026quot;Pharrell Williams\u0026quot;, song = \u0026quot;Happy\u0026quot;) pharrell_will_happy ## # A tibble: 67 x 3 ## track_title line lyric ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 Happy 1 \u0026lt;NA\u0026gt; ## 2 Happy 2 It might seem crazy what I\u0026#39;m \u0026#39;bout to say ## 3 Happy 3 Sunshine she\u0026#39;s here, you can take a break ## 4 Happy 4 I\u0026#39;m a hot air balloon that could go to space ## 5 Happy 5 With the air, like I don\u0026#39;t care, baby, by the way ## 6 Happy 6 (Because I\u0026#39;m happy) ## 7 Happy 7 Clap along if you feel like a room without a roof ## 8 Happy 8 (Because I\u0026#39;m happy) ## 9 Happy 9 Clap along if you feel like happiness is the truth ## 10 Happy 10 (Because I\u0026#39;m happy) ## # … with 57 more rows happy_tidy \u0026lt;- pharrell_will_happy %\u0026gt;% select(lyric, track_title) %\u0026gt;% unnest_tokens(word, lyric) happy_tidy ## # A tibble: 473 x 2 ## track_title word ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Happy \u0026lt;NA\u0026gt; ## 2 Happy it ## 3 Happy might ## 4 Happy seem ## 5 Happy crazy ## 6 Happy what ## 7 Happy i\u0026#39;m ## 8 Happy bout ## 9 Happy to ## 10 Happy say ## # … with 463 more rows happy_sentiments\u0026lt;- happy_tidy%\u0026gt;% inner_join(get_sentiments(\u0026quot;bing\u0026quot;), by = c(word = \u0026quot;word\u0026quot;)) happy_sentiments ## # A tibble: 63 x 3 ## track_title word sentiment ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Happy crazy negative ## 2 Happy break negative ## 3 Happy hot positive ## 4 Happy like positive ## 5 Happy happy positive ## 6 Happy like positive ## 7 Happy happy positive ## 8 Happy like positive ## 9 Happy happiness positive ## 10 Happy happy positive ## # … with 53 more rows happy_sentiments %\u0026gt;% count(sentiment, word) %\u0026gt;% ungroup() %\u0026gt;% mutate(n = ifelse(sentiment == \u0026quot;negative\u0026quot;, -n, n)) %\u0026gt;% mutate(word = reorder(word, n)) %\u0026gt;% ggplot(aes(word, n, fill = sentiment)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + ylab(\u0026quot;Contribution to sentiment\u0026quot;) + coord_flip() Summertime Sadness – Lana Del Rey   Summertime_Sadness \u0026lt;- genius_lyrics(artist = \u0026quot;Lana Del Rey\u0026quot;, song = \u0026quot;Summertime Sadness\u0026quot;) Summertime_Sadness ## # A tibble: 54 x 3 ## track_title line lyric ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; ## 1 Summertime Sadness 1 Kiss me hard before you go ## 2 Summertime Sadness 2 Summertime sadness ## 3 Summertime Sadness 3 I just wanted you to know ## 4 Summertime Sadness 4 That, baby, you\u0026#39;re the best ## 5 Summertime Sadness 5 I got my red dress on tonight ## 6 Summertime Sadness 6 Dancin\u0026#39; in the dark in the pale moonlight ## 7 Summertime Sadness 7 Done my hair up real big, beauty queen style ## 8 Summertime Sadness 8 High heels off, I\u0026#39;m feelin\u0026#39; alive ## 9 Summertime Sadness 9 Oh, my God, I feel it in the air ## 10 Summertime Sadness 10 Telephone wires above are sizzlin\u0026#39; like a snare ## # … with 44 more rows Summertime_Sadness_tidy \u0026lt;- Summertime_Sadness %\u0026gt;% select(lyric, track_title) %\u0026gt;% unnest_tokens(word, lyric) Summertime_Sadness_tidy ## # A tibble: 312 x 2 ## track_title word ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Summertime Sadness kiss ## 2 Summertime Sadness me ## 3 Summertime Sadness hard ## 4 Summertime Sadness before ## 5 Summertime Sadness you ## 6 Summertime Sadness go ## 7 Summertime Sadness summertime ## 8 Summertime Sadness sadness ## 9 Summertime Sadness i ## 10 Summertime Sadness just ## # … with 302 more rows Summertime_Sadness_sentiments\u0026lt;- Summertime_Sadness_tidy%\u0026gt;% inner_join(get_sentiments(\u0026quot;bing\u0026quot;), by = c(word = \u0026quot;word\u0026quot;)) Summertime_Sadness_sentiments ## # A tibble: 39 x 3 ## track_title word sentiment ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; ## 1 Summertime Sadness hard negative ## 2 Summertime Sadness sadness negative ## 3 Summertime Sadness best positive ## 4 Summertime Sadness dark negative ## 5 Summertime Sadness pale negative ## 6 Summertime Sadness beauty positive ## 7 Summertime Sadness like positive ## 8 Summertime Sadness snare negative ## 9 Summertime Sadness hard negative ## 10 Summertime Sadness sadness negative ## # … with 29 more rows Summertime_Sadness_sentiments %\u0026gt;% count(sentiment, word) %\u0026gt;% ungroup() %\u0026gt;% mutate(n = ifelse(sentiment == \u0026quot;negative\u0026quot;, -n, n)) %\u0026gt;% mutate(word = reorder(word, n)) %\u0026gt;% ggplot(aes(word, n, fill = sentiment)) + geom_bar(stat = \u0026quot;identity\u0026quot;) + ylab(\u0026quot;Contribution to sentiment\u0026quot;) + coord_flip()  ","date":1591660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591767961,"objectID":"71d1a26f7bb4164ad57cafc11f7bfba0","permalink":"/post/2020-06-09-sentiment-analysis.en/sentiment-analysis/","publishdate":"2020-06-09T00:00:00Z","relpermalink":"/post/2020-06-09-sentiment-analysis.en/sentiment-analysis/","section":"post","summary":"The TF-IDF is computed by multiplying two terms:TF and IDF. TF is the normalized term frequency and IDF is the inverse document frequency. Therefore, the formula for TF-IDF is TFxIDF","tags":["NLP"],"title":"TF-IDF \u0026 Sentiment Analysis ","type":"post"},{"authors":[],"categories":[],"content":" For this project, I am selecting four books from Project Gutenberg library from sub-categories: Crime, Music, Astronomy and Revolution. The purpose of the project is to perform topic modeling using LDA algorithm to see whether it can correctly distinguish the four groups.\nTopic modeling is an unsupervised machine learning technique for text data. It scans a set of documents(book chapters in this case), detecting word and phrase patterns within them, and clustering word groups and similar expressions that best characterize a set of documents.Latent Dirichlet Allocation (LDA) is an example of topic modeling algorithm used to cluster text in a document to a particular topic. It is guided by two principles - every document is a mixture of topics and every topic is a mixture of words.\nStep-by-step explanations are as follows:\nlibrary(pacman) p_load(topicmodels,gutenbergr,tidyverse,tidytext,stringr,scales) 1.Book Titles\n# four books for topic models titles \u0026lt;- c(\u0026quot;Buccaneers and Pirates of Our Coasts\u0026quot;, \u0026quot;Beethoven\u0026quot;, \u0026quot;Astronomy for Amateurs\u0026quot;,\u0026quot;The Psychology of Revolution\u0026quot;) titles ## [1] \u0026quot;Buccaneers and Pirates of Our Coasts\u0026quot; ## [2] \u0026quot;Beethoven\u0026quot; ## [3] \u0026quot;Astronomy for Amateurs\u0026quot; ## [4] \u0026quot;The Psychology of Revolution\u0026quot; # retrieve books from gutenbergr books \u0026lt;- gutenberg_download(c(448,15141,25267,17188), meta_fields = \u0026quot;title\u0026quot;) 2.Pre-Processing\n# divide into documents, each representing one chapter by_chapter \u0026lt;- books %\u0026gt;% group_by(title) %\u0026gt;% mutate(chapter = cumsum(str_detect(text, regex(\u0026quot;^chapter \u0026quot;, ignore_case = TRUE)))) %\u0026gt;% ungroup() %\u0026gt;% filter(chapter \u0026gt; 0) %\u0026gt;% unite(document, title, chapter) # split into words by_chapter_word \u0026lt;- by_chapter %\u0026gt;% unnest_tokens(word, text) # find document-word counts word_counts \u0026lt;- by_chapter_word %\u0026gt;% anti_join(stop_words) %\u0026gt;% count(document, word, sort = TRUE) %\u0026gt;% ungroup() ## Joining, by = \u0026quot;word\u0026quot; word_counts ## # A tibble: 67,284 x 3 ## document word n ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s indeb… beethov… 87 ## 2 Astronomy for Amateurs_11 distance 77 ## 3 Astronomy for Amateurs_4 sun 66 ## 4 Astronomy for Amateurs_9 moon 64 ## 5 Astronomy for Amateurs_3 stars 63 ## 6 Astronomy for Amateurs_11 sun 58 ## 7 Astronomy for Amateurs_8 earth 56 ## 8 Astronomy for Amateurs_10 sun 54 ## 9 Astronomy for Amateurs_2 stars 53 ## 10 The Psychology of Revolution_53 revolut… 52 ## # … with 67,274 more rows 3.LDA on Chapters\n# convert tidy data to document term matrix chapters_dtm \u0026lt;- word_counts %\u0026gt;% cast_dtm(document, word, n) chapters_dtm ## \u0026lt;\u0026lt;DocumentTermMatrix (documents: 117, terms: 16265)\u0026gt;\u0026gt; ## Non-/sparse entries: 67284/1835721 ## Sparsity : 96% ## Maximal term length: 41 ## Weighting : term frequency (tf) # create topic model with LDA function for four books, k = 4 chapters_lda \u0026lt;- LDA(chapters_dtm, k = 4, control = list(seed = 1999)) chapters_lda ## A LDA_VEM topic model with 4 topics. #per-topic-per-word probabilities : beta chapter_topics \u0026lt;- tidy(chapters_lda, matrix = \u0026quot;beta\u0026quot;) chapter_topics ## # A tibble: 65,060 x 3 ## topic term beta ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 beethoven 6.55e-135 ## 2 2 beethoven 4.39e- 18 ## 3 3 beethoven 1.34e-132 ## 4 4 beethoven 2.09e- 2 ## 5 1 distance 7.99e- 4 ## 6 2 distance 9.49e- 5 ## 7 3 distance 7.75e- 3 ## 8 4 distance 7.62e- 5 ## 9 1 sun 8.19e- 5 ## 10 2 sun 3.16e- 5 ## # … with 65,050 more rows For example, the term “beethoven” has zero probability of being generated from topics 1, 3, or 4, but it makes up 2% of topic 2.\n# top 10 terms in each topic top_terms \u0026lt;- chapter_topics %\u0026gt;% group_by(topic) %\u0026gt;% top_n(10, beta) %\u0026gt;% ungroup() %\u0026gt;% arrange(topic, -beta) top_terms ## # A tibble: 40 x 3 ## topic term beta ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 pirate 0.0117 ## 2 1 pirates 0.0108 ## 3 1 town 0.00865 ## 4 1 vessel 0.00851 ## 5 1 ship 0.00733 ## 6 1 buccaneers 0.00622 ## 7 1 time 0.00606 ## 8 1 captain 0.00602 ## 9 1 spanish 0.00585 ## 10 1 people 0.00483 ## # … with 30 more rows # visualize top terms from each topic top_terms %\u0026gt;% mutate(term = reorder_within(term, beta, topic)) %\u0026gt;% ggplot(aes(term, beta, fill = factor(topic))) + geom_col(show.legend = F) + facet_wrap(~topic, scales = \u0026quot;free\u0026quot;) + coord_flip() + scale_x_reordered() + labs(caption = \u0026quot;Fig:The terms that are most common within each topic\u0026quot;) + theme(plot.caption = element_text(hjust = 0.5, size = 10)) The topics are clearly associated with the four books.\n4.Per-document Classification\n#per-document-per-topic probabilities: gamma chapters_gamma \u0026lt;- tidy(chapters_lda, matrix = \u0026quot;gamma\u0026quot;) chapters_gamma ## # A tibble: 468 x 3 ## document topic gamma ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s inde… 1 4.05e-6 ## 2 Astronomy for Amateurs_11 1 7.54e-6 ## 3 Astronomy for Amateurs_4 1 9.32e-6 ## 4 Astronomy for Amateurs_9 1 1.05e-5 ## 5 Astronomy for Amateurs_3 1 8.14e-6 ## 6 Astronomy for Amateurs_8 1 8.58e-6 ## 7 Astronomy for Amateurs_10 1 8.42e-6 ## 8 Astronomy for Amateurs_2 1 9.93e-6 ## 9 The Psychology of Revolution_53 1 7.75e-6 ## 10 Buccaneers and Pirates of Our Coasts_33 1 10.00e-1 ## # … with 458 more rows Astronomy for Amateurs_11 document has 0% probability of coming from topic 1(Buccaneers and Pirates of Our Coasts).\n#separate out chapter and title chapters_gamma \u0026lt;- chapters_gamma %\u0026gt;% separate(document, c(\u0026quot;title\u0026quot;, \u0026quot;chapter\u0026quot;), sep= \u0026quot;_\u0026quot;, convert = TRUE) chapters_gamma ## # A tibble: 468 x 4 ## title chapter topic gamma ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagne… 19 1 4.05e-6 ## 2 Astronomy for Amateurs 11 1 7.54e-6 ## 3 Astronomy for Amateurs 4 1 9.32e-6 ## 4 Astronomy for Amateurs 9 1 1.05e-5 ## 5 Astronomy for Amateurs 3 1 8.14e-6 ## 6 Astronomy for Amateurs 8 1 8.58e-6 ## 7 Astronomy for Amateurs 10 1 8.42e-6 ## 8 Astronomy for Amateurs 2 1 9.93e-6 ## 9 The Psychology of Revolution 53 1 7.75e-6 ## 10 Buccaneers and Pirates of Our Coasts 33 1 10.00e-1 ## # … with 458 more rows # reorder titles and plot chapters_gamma %\u0026gt;% mutate(title = reorder(title, gamma*topic)) %\u0026gt;% ggplot(aes(factor(topic),gamma)) + geom_boxplot() + facet_wrap(~title) + labs(caption = \u0026quot;Fig: The gamma probabilities for each chapter within each book\u0026quot;) + theme(plot.caption = element_text(hjust = 0.5, size = 12)) It appears all of the chapters are uniquely identified as a single topic.\n#topic most associated with a chapter chapter_classifications \u0026lt;- chapters_gamma %\u0026gt;% group_by(title, chapter) %\u0026gt;% top_n(1, gamma) %\u0026gt;% ungroup() chapter_classifications ## # A tibble: 117 x 4 ## title chapter topic gamma ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 Buccaneers and Pirates of Our Coasts 33 1 1.000 ## 2 Buccaneers and Pirates of Our Coasts 11 1 1.000 ## 3 Buccaneers and Pirates of Our Coasts 31 1 1.000 ## 4 Buccaneers and Pirates of Our Coasts 32 1 0.981 ## 5 Buccaneers and Pirates of Our Coasts 30 1 1.000 ## 6 Buccaneers and Pirates of Our Coasts 20 1 1.000 ## 7 Buccaneers and Pirates of Our Coasts 21 1 1.000 ## 8 Buccaneers and Pirates of Our Coasts 23 1 1.000 ## 9 Buccaneers and Pirates of Our Coasts 15 1 1.000 ## 10 Buccaneers and Pirates of Our Coasts 16 1 1.000 ## # … with 107 more rows # consensus topics book_topics \u0026lt;- chapter_classifications %\u0026gt;% count(title, topic) %\u0026gt;% group_by(title) %\u0026gt;% top_n(1,n) %\u0026gt;% ungroup() %\u0026gt;% transmute(consensus = title, topic) book_topics%\u0026gt;% arrange((topic)) ## # A tibble: 4 x 2 ## consensus topic ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 Buccaneers and Pirates of Our Coasts 1 ## 2 The Psychology of Revolution 2 ## 3 Astronomy for Amateurs 3 ## 4 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s indebtedness to… 4 #misidentified topics chapter_classifications %\u0026gt;% inner_join(book_topics, by = \u0026quot;topic\u0026quot;) %\u0026gt;% filter(title != consensus) ## # A tibble: 0 x 5 ## # … with 5 variables: title \u0026lt;chr\u0026gt;, chapter \u0026lt;int\u0026gt;, topic \u0026lt;int\u0026gt;, gamma \u0026lt;dbl\u0026gt;, ## # consensus \u0026lt;chr\u0026gt; Indeed, no chapters were mis-classified.\n5.By Word Assignments: Augment\n# see which words are assigned to which topic with augment function assignments \u0026lt;- augment(chapters_lda, data = chapters_dtm) assignments ## # A tibble: 67,284 x 4 ## document term count .topic ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 87 4 ## 2 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 45 4 ## 3 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 44 4 ## 4 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 43 4 ## 5 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 43 4 ## 6 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 39 4 ## 7 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 38 4 ## 8 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 28 4 ## 9 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 25 4 ## 10 \u0026quot;Beethoven, a character study\\r\\nTogether with Wagner\u0026#39;s… beetho… 24 4 ## # … with 67,274 more rows # combine assignments with true book titles to find incorrect classification assignments \u0026lt;- assignments %\u0026gt;% separate(document, c(\u0026quot;title\u0026quot;, \u0026quot;chapter\u0026quot;), sep = \u0026quot;_\u0026quot;, convert = TRUE)%\u0026gt;% inner_join(book_topics, by = c(\u0026quot;.topic\u0026quot; = \u0026quot;topic\u0026quot;)) assignments ## # A tibble: 67,284 x 6 ## title chapter term count .topic consensus ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 \u0026quot;Beethoven, a characte… 19 beeth… 87 4 \u0026quot;Beethoven, a character … ## 2 \u0026quot;Beethoven, a characte… 13 beeth… 45 4 \u0026quot;Beethoven, a character … ## 3 \u0026quot;Beethoven, a characte… 8 beeth… 44 4 \u0026quot;Beethoven, a character … ## 4 \u0026quot;Beethoven, a characte… 1 beeth… 43 4 \u0026quot;Beethoven, a character … ## 5 \u0026quot;Beethoven, a characte… 6 beeth… 43 4 \u0026quot;Beethoven, a character … ## 6 \u0026quot;Beethoven, a characte… 2 beeth… 39 4 \u0026quot;Beethoven, a character … ## 7 \u0026quot;Beethoven, a characte… 10 beeth… 38 4 \u0026quot;Beethoven, a character … ## 8 \u0026quot;Beethoven, a characte… 5 beeth… 28 4 \u0026quot;Beethoven, a character … ## 9 \u0026quot;Beethoven, a characte… 11 beeth… 25 4 \u0026quot;Beethoven, a character … ## 10 \u0026quot;Beethoven, a characte… 14 beeth… 24 4 \u0026quot;Beethoven, a character … ## # … with 67,274 more rows #visualize a confusion matrix assignments %\u0026gt;% count(title, consensus, wt = count) %\u0026gt;% group_by(title) %\u0026gt;% mutate(percent = n / sum(n)) %\u0026gt;% ggplot(aes(consensus, title, fill = percent)) + geom_tile() + scale_fill_gradient2(high = \u0026quot;blue\u0026quot;, label = percent_format()) + theme_minimal() + theme(axis.text.x = element_text(angle = 90, hjust = 1), panel.grid = element_blank()) + labs(x = \u0026quot;book words were assigned to\u0026quot;, y = \u0026quot;book words came from\u0026quot;, fill = \u0026quot;% of assignments\u0026quot;) + labs(caption = \u0026quot;Fig: Confusion matrix showing where LDA assigned the words from each book\u0026quot;) + theme(plot.caption = element_text( size = 10),legend.key.size = unit(0.5, \u0026quot;cm\u0026quot;))  Almost all words were correctly assigned to each topic.\n# most commonly mistaken words wrong_words \u0026lt;- assignments %\u0026gt;% filter(title!= consensus) wrong_words ## # A tibble: 45 x 6 ## title chapter term count .topic consensus ## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 Buccaneers and Pirates… 32 moon 3 3 Astronomy for Amateurs ## 2 Buccaneers and Pirates… 32 stars 2 3 Astronomy for Amateurs ## 3 \u0026quot;Beethoven, a characte… 4 revol… 1 2 The Psychology of Revolu… ## 4 The Psychology of Revo… 45 capta… 1 1 Buccaneers and Pirates o… ## 5 The Psychology of Revo… 45 town 2 1 Buccaneers and Pirates o… ## 6 Buccaneers and Pirates… 32 heave… 1 3 Astronomy for Amateurs ## 7 The Psychology of Revo… 45 vessel 1 1 Buccaneers and Pirates o… ## 8 \u0026quot;Beethoven, a characte… 4 armies 2 2 The Psychology of Revolu… ## 9 Buccaneers and Pirates… 1 1 1 4 \u0026quot;Beethoven, a character … ## 10 \u0026quot;Beethoven, a characte… 4 bonap… 3 2 The Psychology of Revolu… ## # … with 35 more rows wrong_words %\u0026gt;% count(title, consensus, term , wt = count) %\u0026gt;% ungroup() %\u0026gt;% arrange(-n) ## # A tibble: 45 x 4 ## title consensus term n ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 \u0026quot;Beethoven, a character study\\r\\nTogeth… The Psychology of Revo… france 6 ## 2 \u0026quot;Beethoven, a character study\\r\\nTogeth… The Psychology of Revo… bonap… 3 ## 3 Buccaneers and Pirates of Our Coasts Astronomy for Amateurs moon 3 ## 4 \u0026quot;Beethoven, a character study\\r\\nTogeth… The Psychology of Revo… armies 2 ## 5 \u0026quot;Beethoven, a character study\\r\\nTogeth… The Psychology of Revo… louis 2 ## 6 Buccaneers and Pirates of Our Coasts Astronomy for Amateurs stars 2 ## 7 The Psychology of Revolution Buccaneers and Pirates… town 2 ## 8 \u0026quot;Beethoven, a character study\\r\\nTogeth… The Psychology of Revo… equal… 1 ## 9 \u0026quot;Beethoven, a character study\\r\\nTogeth… The Psychology of Revo… gover… 1 ## 10 \u0026quot;Beethoven, a character study\\r\\nTogeth… The Psychology of Revo… illus… 1 ## # … with 35 more rows The word “moon” and “stars” appear in “Buccaneers and Pirates of Our Coasts” but they are wrongly classified into “Astronomy for Amateurs” becuase they are more common in the later.\n# wrongly classified word, eg. \u0026quot;moon\u0026quot; word_counts %\u0026gt;% filter(word == \u0026quot;moon\u0026quot;) ## # A tibble: 12 x 3 ## document word n ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; ## 1 Astronomy for Amateurs_9 moon 64 ## 2 Astronomy for Amateurs_10 moon 49 ## 3 Astronomy for Amateurs_11 moon 35 ## 4 Astronomy for Amateurs_4 moon 10 ## 5 Astronomy for Amateurs_12 moon 9 ## 6 Astronomy for Amateurs_5 moon 8 ## 7 Astronomy for Amateurs_8 moon 4 ## 8 Astronomy for Amateurs_3 moon 3 ## 9 Astronomy for Amateurs_6 moon 3 ## 10 Buccaneers and Pirates of Our Coasts_32 moon 3 ## 11 Astronomy for Amateurs_1 moon 2 ## 12 Astronomy for Amateurs_7 moon 2 Although the words are presumably different for each topic since books are selected from different genre, LDA algorithm performed really well on identifying topics to the document and words to the topic. Really great for unsupervised clustering!\n","date":1591660800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591759060,"objectID":"329cefb33c2c8be1b997119e1e0a83c0","permalink":"/post/r-markdown/","publishdate":"2020-06-09T00:00:00Z","relpermalink":"/post/r-markdown/","section":"post","summary":"For this project, I am selecting four books from Project Gutenberg library from sub-categories: Crime, Music, Astronomy and Revolution. The purpose of the project is to perform topic modeling using LDA algorithm to see whether it can correctly distinguish the four groups.","tags":["R"],"title":"Topic Modeling","type":"post"},{"authors":null,"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"3960dd3bdc6f629fb800d1d2aaa7224f","permalink":"/resume/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/resume/","section":"","summary":"Resume","tags":null,"title":"Resume","type":"widget_page"},{"authors":["minr"],"categories":["Data Viz"],"content":" Statebins are U.S. State Cartogram Heatmaps, alternative to Choropleth.\n# load packages library(pacman) p_load(statebins,readxl,dplyr) Statebins with 2018 Bachelor’s Degree or Higher by State (percent) data.\n# upload data data1 \u0026lt;- read_excel(\u0026quot;GeoFRED_Bachelor\u0026#39;s_Degree_or_Higher_by_State_Percent.xls\u0026quot;, skip = 1) data1 %\u0026gt;% sample_n(5) ## # A tibble: 5 x 4 ## `Series ID` State Code Year_2018 ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 GCT1502WA Washington 53 36.7 ## 2 GCT1502WV West Virginia 54 21.3 ## 3 GCT1502VA Virginia 51 39.3 ## 4 GCT1502AZ Arizona 04 29.7 ## 5 GCT1502HI Hawaii 15 33.5 # statebins statebins_continuous(state_data = data1, state_col = \u0026quot;State\u0026quot;, text_color = \u0026quot;white\u0026quot;, value_col = \u0026quot;Year_2018\u0026quot;, brewer_pal=\u0026quot;Blues\u0026quot;, font_size = 3, legend_title=\u0026quot;2018 Bachelor\u0026#39;s Degree or Higher by State (percent)\u0026quot;) Statebins with 2018 Median Household Income by State Data\ndata2 \u0026lt;- read_excel(\u0026quot;GeoFRED_Median_Household_Income_by_State_Percent_Change.xls\u0026quot;, skip = 1) data2 %\u0026gt;% sample_n(5) ## # A tibble: 5 x 4 ## `Series ID` State Code Year_2018 ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 MEHOINUSDCA646N District of Columbia 11 5.50 ## 2 MEHOINUSVTA646N Vermont 50 10.0 ## 3 MEHOINUSPAA646N Pennsylvania 42 5.29 ## 4 MEHOINUSNEA646N Nebraska 31 13.4 ## 5 MEHOINUSINA646N Indiana 18 1.91 statebins_continuous(state_data = data2, state_col = \u0026quot;State\u0026quot;, text_color = \u0026quot;white\u0026quot;, value_col = \u0026quot;Year_2018\u0026quot;, brewer_pal=\u0026quot;Greens\u0026quot;, font_size = 3, legend_title=\u0026quot; Median Household Income by State\u0026quot;) ## Warning: `show_guide` has been deprecated. Please use `show.legend` instead. Statebins with 2018 Resident Population by State (change, thousands of persons) Data\ndata3 \u0026lt;- read_excel(\u0026quot;GeoFRED_Resident_Population_by_State_Change_Thousands_of_Persons.xls\u0026quot;, skip=1) data3 %\u0026gt;% sample_n(5) ## # A tibble: 5 x 4 ## `Series ID` State Code Year_2018 ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 TNPOP Tennessee 47 61.2 ## 2 DCDIST5POP District of Columbia 11 6.76 ## 3 NEPOP Nebraska 31 11.7 ## 4 AKPOP Alaska 02 -2.35 ## 5 TXPOP Texas 48 379. statebins_continuous(state_data = data3, state_col = \u0026quot;State\u0026quot;, text_color = \u0026quot;white\u0026quot;, value_col = \u0026quot;Year_2018\u0026quot;, brewer_pal=\u0026quot;Reds\u0026quot;, font_size = 3, legend_title=\u0026quot;2018 Resident Population by State (change, thousands of persons) \u0026quot;) ## Warning: `show_guide` has been deprecated. Please use `show.legend` instead. ","date":1575943994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575943994,"objectID":"d7925e618b32cfa3bbd60cad8f4752e9","permalink":"/post/statebins/","publishdate":"2019-12-09T21:13:14-05:00","relpermalink":"/post/statebins/","section":"post","summary":"Statebins using data from GeoFRED","tags":["Data Viz"],"title":"Statebins","type":"post"},{"authors":["minr"],"categories":["Data Viz"],"content":" Choropleth maps add color to states or countries relative to a variable.\nlibrary(pacman) p_load(tidyverse, choroplethr, choroplethrMaps,RColorBrewer) State Population\ndata(df_pop_state) pop_state \u0026lt;- df_pop_state %\u0026gt;% arrange(-(value)) top_n(pop_state,10) ## Selecting by value ## region value ## 1 california 37325068 ## 2 texas 25208897 ## 3 new york 19398125 ## 4 florida 18885152 ## 5 illinois 12823860 ## 6 pennsylvania 12699589 ## 7 ohio 11533561 ## 8 michigan 9897264 ## 9 georgia 9714569 ## 10 north carolina 9544249 state_choropleth(df_pop_state, title = \u0026quot;US 2012 State Population Estimates\u0026quot;, legend = \u0026quot;Population\u0026quot;) County Population\ndata(df_pop_county) county_choropleth(df_pop_county, title = \u0026quot;US 2012 County Population Estimates\u0026quot;, legend = \u0026quot;Population\u0026quot;, num_colors = 8) California Counties\ncounty_choropleth(df_pop_county, title = \u0026quot;California County Population Estimates\u0026quot;, legend = \u0026quot;Population\u0026quot;, state_zoom = \u0026quot;california\u0026quot;) State Demographics\ndata(\u0026quot;df_state_demographics\u0026quot;) head(df_state_demographics,10) ## region total_population percent_white percent_black ## 1 alabama 4799277 67 26 ## 2 alaska 720316 63 3 ## 3 arizona 6479703 57 4 ## 4 arkansas 2933369 74 15 ## 5 california 37659181 40 6 ## 6 colorado 5119329 70 4 ## 7 connecticut 3583561 70 9 ## 8 delaware 908446 65 21 ## 9 district of columbia 619371 35 49 ## 10 florida 19091156 57 15 ## percent_asian percent_hispanic per_capita_income median_rent median_age ## 1 1 4 23680 501 38.1 ## 2 5 6 32651 978 33.6 ## 3 3 30 25358 747 36.3 ## 4 1 7 22170 480 37.5 ## 5 13 38 29527 1119 35.4 ## 6 3 21 31109 825 36.1 ## 7 4 14 37892 880 40.2 ## 8 3 8 29819 828 38.9 ## 9 3 10 45290 1154 33.8 ## 10 2 23 26236 838 41.0 # African American Population Distribution df_state_demographics$value\u0026lt;- df_state_demographics$percent_black state_choropleth(df_state_demographics, title = \u0026quot;African American Population Distribution in US\u0026quot;, legend = \u0026quot;Population\u0026quot;) # White Population Distribution df_state_demographics$value\u0026lt;- df_state_demographics$percent_white state_choropleth(df_state_demographics, title = \u0026quot;White Population Distribution in US\u0026quot;, legend = \u0026quot;Population\u0026quot;) # Asian Population Distribution df_state_demographics$value\u0026lt;- df_state_demographics$percent_asian state_choropleth(df_state_demographics, title = \u0026quot;Asian Population Distribution in US\u0026quot;, legend = \u0026quot;Population\u0026quot;) World Map\ndata(\u0026quot;df_pop_country\u0026quot;) country_pop \u0026lt;- df_pop_country %\u0026gt;% arrange(desc(value)) head(country_pop,10) ## region value ## 1 china 1350695000 ## 2 india 1236686732 ## 3 united states of america 313873685 ## 4 indonesia 246864191 ## 5 brazil 198656019 ## 6 pakistan 179160111 ## 7 nigeria 168833776 ## 8 bangladesh 154695368 ## 9 russia 143178000 ## 10 japan 127561489 country_choropleth(country_pop, title = \u0026quot;World map based on population estimates\u0026quot;, legend = \u0026quot;Population\u0026quot;) ## Warning in self$bind(): The following regions were missing and are being set to ## NA: namibia, western sahara, taiwan, antarctica, kosovo ","date":1574129594,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574129594,"objectID":"d1c8d7474b55c917fac2d05f69065370","permalink":"/post/choropleth/","publishdate":"2019-11-18T21:13:14-05:00","relpermalink":"/post/choropleth/","section":"post","summary":"Choropleth maps with population data","tags":["Data Viz"],"title":"Choropleth Map","type":"post"},{"authors":[""],"categories":null,"content":" Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[""],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[""],"title":"An example journal article","type":"publication"},{"authors":["","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[""],"title":"An example conference paper","type":"publication"}]